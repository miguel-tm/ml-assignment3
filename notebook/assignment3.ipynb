{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3 - Dimensionality Reduction\n",
    "### Miguel Morales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is based on content discussed in module 6 and will work with the famous MNIST dataset, which is a set of images of handwritten digits https://en.wikipedia.org/wiki/MNIST_database.\n",
    "The dataset has been provided to you in a .csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply a Random Forest classification algorithm to MNIST dataset\n",
    "- Perform dimensionality reduction of features using PCA and compare classification on the reduced dataset to that of original one\n",
    "- Apply dimensionality reduction techniques: t-SNE and LLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports for the assignment\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions (15 points total)\n",
    "\n",
    "__Question 1 (1 point).__ Load the MNIST dataset and split it into a training set and a test set (take the first 60,000 instances for training, and the remaining 10,000 for testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (X_train): 60000 samples\n",
      "Test set (X_test): 10000 samples\n",
      "Number of features: 784\n",
      "Labels in training set (the digits): [2 5 8 0 4 6 7 1 9 3]\n"
     ]
    }
   ],
   "source": [
    "# Analyzing the MNIST dataset (from the description on the Wikipedia page), and looking into its structure, we can determine the following:\n",
    "# Columns:\n",
    "# - Index column (unnamed): Row numbers 0-69,999\n",
    "# - label column: The target variable (y): it contains the actual digit (0-9) that each image represents\n",
    "# - 784 pixel columns: Named as 1x1, 1x2, 1x3, ..., 28x28\n",
    "# -- These represent pixel intensity values from a 28×28 grayscale image (28*28 = 784)\n",
    "# -- Each pixel value ranges from 0 (black) to 255 (white)\n",
    "# -- The naming convention rowXcolumn indicates the position in the 28×28 grid\n",
    "\n",
    "# Loading the MNIST dataset\n",
    "mnist = pd.read_csv('../data/mnist_dataset.csv', index_col=0)\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = mnist.drop('label', axis=1)\n",
    "y = mnist['label']\n",
    "\n",
    "# Splitting into training (first 60,000) and test (remaining 10,000) sets\n",
    "\n",
    "# Training set: first 60,000 samples\n",
    "X_train = X[:60000]\n",
    "y_train = y[:60000]\n",
    "# Test set: remaining 10,000 samples\n",
    "X_test = X[60000:]\n",
    "y_test = y[60000:]\n",
    "\n",
    "# Displaying the shapes to verify the split\n",
    "print(f\"Training set (X_train): {X_train.shape[0]} samples\")\n",
    "print(f\"Test set (X_test): {X_test.shape[0]} samples\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")\n",
    "print(f\"Labels in training set (the digits 0-9): {y_train.unique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2 (2 points).__ Train a Random Forest classifier on the dataset and time how long it takes, then evaluate the resulting model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3 (4 points).__ Next, use PCA to reduce the dataset’s dimensionality, with an explained variance ratio of 95%. Train a new Random Forest classifier on the reduced dataset and see how long it takes. Was training much faster? Next evaluate the classifier on the test set: how does it compare to the previous classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 4 (4 points).__ Use t-SNE to reduce the MNIST dataset, show result graphically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 5 (4 points).__ Compare with other dimensionality methods: _Locally Linear Embedding_ (LLE) or _Multidimensional scaling_ (MDS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Assignment 3 -- Dimensionality Reduction\n",
    "\n",
    "# This assignment is based on content discussed in module 6 and will work with the famous MNIST dataset, which is a set of images of handwritten digits https://en.wikipedia.org/wiki/MNIST_database.\n",
    "# The dataset has been provided to you in a .csv file.\n",
    "\n",
    "## Learning outcomes\n",
    "\n",
    "# - Apply a Random Forest classification algorithm to MNIST dataset\n",
    "# - Perform dimensionality reduction of features using PCA and compare classification on the reduced dataset to that of original one\n",
    "# - Apply dimensionality reduction techniques: t-SNE and LLE\n",
    "\n",
    "## Questions (15 points total)\n",
    "\n",
    "#__Question 1 (1 point).__ Load the MNIST dataset and split it into a training set and a test set (take the first 60,000 instances for training,\n",
    "# and the remaining 10,000 for testing).\n",
    "\n",
    "#__Question 2 (2 points).__ Train a Random Forest classifier on the dataset and time how long it takes, \n",
    "#then evaluate the resulting model on the test set.\n",
    "\n",
    "#__Question 3 (4 points).__ Next, use PCA to reduce the dataset’s dimensionality, with an explained variance ratio of 95%. \n",
    "#Train a new Random Forest classifier on the reduced dataset and see how long it takes. Was training much faster?\n",
    "#Next evaluate the classifier on the test set: how does it compare to the previous classifier?\n",
    "\n",
    "#__Question 4 (4 points).__ Use t-SNE to reduce the MNIST dataset, show result graphically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
